word	count	freq
	1139	0.6614401858304297
=	42	0.024390243902439025
+	25	0.014518002322880372
in	12	0.006968641114982578
{}	12	0.006968641114982578
t	11	0.006387921022067364
import	10	0.005807200929152149
for	10	0.005807200929152149
#	9	0.005226480836236934
if	9	0.005226480836236934
train	7	0.0040650406504065045
else:	7	0.0040650406504065045
out_fname	7	0.0040650406504065045
training_data	7	0.0040650406504065045
output	6	0.003484320557491289
model	6	0.003484320557491289
from	5	0.0029036004645760743
subs	5	0.0029036004645760743
subtitle	5	0.0029036004645760743
int(t['duration'])))	5	0.0029036004645760743
as	4	0.0023228803716608595
def	4	0.0023228803716608595
training_data.replace('.txt',	4	0.0023228803716608595
sp.run(binary	4	0.0023228803716608595
return	4	0.0023228803716608595
language	4	0.0023228803716608595
results,	4	0.0023228803716608595
{}'.format(training_data))	4	0.0023228803716608595
fastText	4	0.0023228803716608595
utf-8	3	0.0017421602787456446
deduplicate	3	0.0017421602787456446
@timer	3	0.0017421602787456446
cores,	3	0.0017421602787456446
binary	3	0.0017421602787456446
method	3	0.0017421602787456446
neg	3	0.0017421602787456446
epoch	3	0.0017421602787456446
dim	3	0.0017421602787456446
vecs	3	0.0017421602787456446
i	3	0.0017421602787456446
d	3	0.0017421602787456446
lang	3	0.0017421602787456446
==	3	0.0017421602787456446
langs	3	0.0017421602787456446
logging.info('skipping	3	0.0017421602787456446
data	3	0.0017421602787456446
phrases	3	0.0017421602787456446
of	3	0.0017421602787456446
action='store_true',	3	0.0017421602787456446
help='do	3	0.0017421602787456446
not	3	0.0017421602787456446
-*-	2	0.0011614401858304297
train_fasttext(training_data,	2	0.0011614401858304297
training_data]	2	0.0011614401858304297
t,	2	0.0011614401858304297
['-output',	2	0.0011614401858304297
str(t)]	2	0.0011614401858304297
logging.getLogger().isEnabledFor(logging.INFO):	2	0.0011614401858304297
stdout=sp.DEVNULL)	2	0.0011614401858304297
model,	2	0.0011614401858304297
build_phrases(training_data,	2	0.0011614401858304297
-	2	0.0011614401858304297
t)	2	0.0011614401858304297
langs:	2	0.0011614401858304297
filename	2	0.0011614401858304297
os.path.join(subs_dir,	2	0.0011614401858304297
'raw')	2	0.0011614401858304297
xml	2	0.0011614401858304297
{}'.format(lang))	2	0.0011614401858304297
lang,	2	0.0011614401858304297
ioformat='txt',	2	0.0011614401858304297
files	2	0.0011614401858304297
file	2	0.0011614401858304297
concatenation')	2	0.0011614401858304297
training	2	0.0011614401858304297
and	2	0.0011614401858304297
results	2	0.0011614401858304297
encoding	2	0.0011614401858304297
at	2	0.0011614401858304297
OpenSubtitles	2	0.0011614401858304297
data')	2	0.0011614401858304297
use	2	0.0011614401858304297
files')	2	0.0011614401858304297
type=int,	2	0.0011614401858304297
help='number	2	0.0011614401858304297
phrase-building	2	0.0011614401858304297
coding:	1	0.0005807200929152149
jvparidon@gmail.com	1	0.0005807200929152149
os	1	0.0005807200929152149
argparse	1	0.0005807200929152149
numpy	1	0.0005807200929152149
np	1	0.0005807200929152149
subprocess	1	0.0005807200929152149
sp	1	0.0005807200929152149
strip_subs	1	0.0005807200929152149
join_subs	1	0.0005807200929152149
utensilities	1	0.0005807200929152149
timer	1	0.0005807200929152149
multiprocessing	1	0.0005807200929152149
cpu_count	1	0.0005807200929152149
logging	1	0.0005807200929152149
logging.basicConfig(format='[{levelname}]	1	0.0005807200929152149
{message}',	1	0.0005807200929152149
style='{',	1	0.0005807200929152149
level=logging.INFO)	1	0.0005807200929152149
d=300,	1	0.0005807200929152149
neg=10,	1	0.0005807200929152149
epoch=10,	1	0.0005807200929152149
t=.0001,	1	0.0005807200929152149
prefix='sub'):	1	0.0005807200929152149
['fasttext']	1	0.0005807200929152149
['skipgram']	1	0.0005807200929152149
['-input',	1	0.0005807200929152149
#model_name	1	0.0005807200929152149
'.neg{}.epoch{}.t{}.{}d'.format(neg,	1	0.0005807200929152149
epoch,	1	0.0005807200929152149
d))	1	0.0005807200929152149
model_name	1	0.0005807200929152149
'{}.{}'.format(prefix,	1	0.0005807200929152149
training_data.split('.')[0])	1	0.0005807200929152149
model_name]	1	0.0005807200929152149
['-neg',	1	0.0005807200929152149
str(neg)]	1	0.0005807200929152149
['-epoch',	1	0.0005807200929152149
str(epoch)]	1	0.0005807200929152149
['-t',	1	0.0005807200929152149
['-dim',	1	0.0005807200929152149
str(d)]	1	0.0005807200929152149
thread	1	0.0005807200929152149
['-thread',	1	0.0005807200929152149
str(cores)]	1	0.0005807200929152149
thread)	1	0.0005807200929152149
thread,	1	0.0005807200929152149
'{}.bin'.format(model_name)	1	0.0005807200929152149
'{}.vec'.format(model_name)	1	0.0005807200929152149
phrase_pass):	1	0.0005807200929152149
base_fname	1	0.0005807200929152149
'')	1	0.0005807200929152149
range(phrase_pass):	1	0.0005807200929152149
(2	1	0.0005807200929152149
**	1	0.0005807200929152149
(phrase_pass	1	0.0005807200929152149
1))	1	0.0005807200929152149
*	1	0.0005807200929152149
100	1	0.0005807200929152149
['word2phrase']	1	0.0005807200929152149
['-train',	1	0.0005807200929152149
'{}.{}pass.d5.t{}.txt'.format(base_fname,	1	0.0005807200929152149
1,	1	0.0005807200929152149
out_fname]	1	0.0005807200929152149
['-min-count',	1	0.0005807200929152149
str(5)]	1	0.0005807200929152149
['-threshold',	1	0.0005807200929152149
fix_encoding(training_data):	1	0.0005807200929152149
'.utf-8.txt')	1	0.0005807200929152149
with	1	0.0005807200929152149
open(training_data,	1	0.0005807200929152149
'r',	1	0.0005807200929152149
encoding='utf-8',	1	0.0005807200929152149
errors='ignore')	1	0.0005807200929152149
in_file,	1	0.0005807200929152149
open(out_fname,	1	0.0005807200929152149
'w',	1	0.0005807200929152149
encoding='utf-8')	1	0.0005807200929152149
out_file:	1	0.0005807200929152149
line	1	0.0005807200929152149
in_file:	1	0.0005807200929152149
out_file.write(line)	1	0.0005807200929152149
generate(lang,	1	0.0005807200929152149
subs_dir,	1	0.0005807200929152149
no_strip,	1	0.0005807200929152149
no_join,	1	0.0005807200929152149
no_dedup,	1	0.0005807200929152149
phrase_pass,	1	0.0005807200929152149
filename='',	1	0.0005807200929152149
subset_years=(0,	1	0.0005807200929152149
2020)):	1	0.0005807200929152149
'all':	1	0.0005807200929152149
reversed(sorted(os.listdir(os.path.join(subs_dir,	1	0.0005807200929152149
'raw'))))	1	0.0005807200929152149
[lang]	1	0.0005807200929152149
prep	1	0.0005807200929152149
'':	1	0.0005807200929152149
no_strip:	1	0.0005807200929152149
xml-stripping')	1	0.0005807200929152149
strip	1	0.0005807200929152149
logging.info('stripping	1	0.0005807200929152149
strip_subs.strip_parallelized(training_data,	1	0.0005807200929152149
cores=cores)	1	0.0005807200929152149
logging.info('stripped	1	0.0005807200929152149
seconds'.format(np.sum(results),	1	0.0005807200929152149
no_join:	1	0.0005807200929152149
join	1	0.0005807200929152149
logging.info('concatenating	1	0.0005807200929152149
join_subs.join_dir(training_data,	1	0.0005807200929152149
'./',	1	0.0005807200929152149
verbose=True,	1	0.0005807200929152149
subset_years=subset_years)	1	0.0005807200929152149
logging.info('concatenated	1	0.0005807200929152149
seconds'.format(results,	1	0.0005807200929152149
'{}.{}-{}.txt'.format(lang,	1	0.0005807200929152149
*subset_years)	1	0.0005807200929152149
no_dedup:	1	0.0005807200929152149
xml-stripping	1	0.0005807200929152149
logging.info('deduplicating	1	0.0005807200929152149
'.dedup.txt')	1	0.0005807200929152149
deduplicate.dedup_file(training_data,	1	0.0005807200929152149
out_fname)	1	0.0005807200929152149
n_lines,	1	0.0005807200929152149
n_duplicates	1	0.0005807200929152149
logging.info('read	1	0.0005807200929152149
lines	1	0.0005807200929152149
removed	1	0.0005807200929152149
duplicates	1	0.0005807200929152149
seconds'.format(n_lines,	1	0.0005807200929152149
n_duplicates,	1	0.0005807200929152149
build	1	0.0005807200929152149
logging.info('building	1	0.0005807200929152149
training_data,	1	0.0005807200929152149
phrase_pass)	1	0.0005807200929152149
logging.info('built	1	0.0005807200929152149
passes	1	0.0005807200929152149
seconds'.format(phrase_pass,	1	0.0005807200929152149
fix	1	0.0005807200929152149
potential	1	0.0005807200929152149
broken	1	0.0005807200929152149
logging.info('checking	1	0.0005807200929152149
(and	1	0.0005807200929152149
fixing)	1	0.0005807200929152149
fix_encoding(training_data)	1	0.0005807200929152149
logging.info('training	1	0.0005807200929152149
on	1	0.0005807200929152149
prefix=f'sub.{subset_years[0]}-{subset_years[1]}')	1	0.0005807200929152149
logging.info('trained	1	0.0005807200929152149
seconds'.format(int(t['duration'])))	1	0.0005807200929152149
logging.info('model	1	0.0005807200929152149
{}'.format(model))	1	0.0005807200929152149
logging.info('word	1	0.0005807200929152149
vectors	1	0.0005807200929152149
{}'.format(vecs))	1	0.0005807200929152149
__name__	1	0.0005807200929152149
'__main__':	1	0.0005807200929152149
argparser	1	0.0005807200929152149
argparse.ArgumentParser(description='generate	1	0.0005807200929152149
a	1	0.0005807200929152149
argparser.add_argument('--lang',	1	0.0005807200929152149
default='en',	1	0.0005807200929152149
help='source	1	0.0005807200929152149
(OpenSubtitles	1	0.0005807200929152149
uses	1	0.0005807200929152149
ISO	1	0.0005807200929152149
639-1	1	0.0005807200929152149
codes,	1	0.0005807200929152149
"all"	1	0.0005807200929152149
all	1	0.0005807200929152149
languages)')	1	0.0005807200929152149
argparser.add_argument('--filename',	1	0.0005807200929152149
default='',	1	0.0005807200929152149
help='filename	1	0.0005807200929152149
skipping	1	0.0005807200929152149
preparation')	1	0.0005807200929152149
argparser.add_argument('--subs_dir',	1	0.0005807200929152149
default='../OpenSubtitles2018',	1	0.0005807200929152149
help='location	1	0.0005807200929152149
argparser.add_argument('--no_strip',	1	0.0005807200929152149
xml-strip	1	0.0005807200929152149
argparser.add_argument('--no_join',	1	0.0005807200929152149
concatenate	1	0.0005807200929152149
argparser.add_argument('--no_dedup',	1	0.0005807200929152149
line-wise')	1	0.0005807200929152149
argparser.add_argument('--phrase_pass',	1	0.0005807200929152149
default='5',	1	0.0005807200929152149
passes,	1	0.0005807200929152149
0	1	0.0005807200929152149
equals	1	0.0005807200929152149
no	1	0.0005807200929152149
(default	1	0.0005807200929152149
5)')	1	0.0005807200929152149
argparser.add_argument('--cores',	1	0.0005807200929152149
default=int(cpu_count()	1	0.0005807200929152149
/	1	0.0005807200929152149
2),	1	0.0005807200929152149
cores	1	0.0005807200929152149
to	1	0.0005807200929152149
the	1	0.0005807200929152149
parts	1	0.0005807200929152149
that	1	0.0005807200929152149
can	1	0.0005807200929152149
be	1	0.0005807200929152149
parallelized')	1	0.0005807200929152149
args	1	0.0005807200929152149
argparser.parse_args()	1	0.0005807200929152149
langs,	1	0.0005807200929152149
generate(**vars(args))	1	0.0005807200929152149
logging.info('generated	1	0.0005807200929152149
sub2vec	1	0.0005807200929152149
seconds'.format(lang,	1	0.0005807200929152149
